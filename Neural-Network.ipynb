{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_sign(array):\n",
    "    # return +1, 0, -1 respect to positive, zero, negtive\n",
    "    return 1.*(array>0) - 1.*(array<0)\n",
    "\n",
    "def column_operate(matrix, threshold = 0.00001):\n",
    "    rm = np.array(matrix) # reduced matrix\n",
    "    fm = np.array(matrix) # filtered matrix\n",
    "    ms = matrix.shape # matrix size\n",
    "    mk = np.ones(matrix.shape) # mask\n",
    "    pv = -1*np.ones((ms[1]), dtype = np.int) # pivots\n",
    "    for t in range(ms[1]):\n",
    "        fm = rm*mk # filtered matrix\n",
    "        if np.abs(fm).max() < threshold:\n",
    "            break\n",
    "        \n",
    "        pr, pc = np.unravel_index(np.abs(fm).argmax(), ms) # pivot row, pivot column\n",
    "        rm[:,pc] /= rm[pr][pc]\n",
    "        multi = np.array(rm[pr])\n",
    "        multi[pc] = 0.\n",
    "        rm -= np.dot(rm[:,pc].reshape((ms[0], 1)), multi.reshape((1, ms[1])))\n",
    "        mk[pr] = 0.\n",
    "        mk[:,pc] = 0.\n",
    "        pv[pc] = pr\n",
    "    \n",
    "    rm = rm[:, pv != -1]\n",
    "    pv = pv[pv != -1]\n",
    "    \n",
    "    return rm, pv\n",
    "\n",
    "def mcmc_normal(targets, drop_t = 10, mean=0., std=1.):\n",
    "    output = np.random.normal(mean, std, targets.shape[1:])\n",
    "    if drop_t>1:\n",
    "        for t in range(1, drop_t):\n",
    "            c = np.random.normal(mean, std/np.sqrt(targets[0].size), targets.shape[1:]) # candicate\n",
    "            cd = np.sqrt(np.square(np.subtract(targets, c)).sum(axis=tuple(np.arange(1,len(targets.shape)))).min())\n",
    "            # distance of candicate to target\n",
    "            od = np.sqrt(np.square(np.subtract(targets, output)).sum(axis=tuple(np.arange(1,len(targets.shape)))).min())\n",
    "            # distance of currently output to target\n",
    "            if np.random.rand()*od < cd:\n",
    "                output = np.array(c)\n",
    "    \n",
    "    return output\n",
    "\n",
    "class VariableArray():\n",
    "    def __init__(self, size, cs_initial=0.1):\n",
    "        self.v = np.random.normal(0., 1., size) # array values\n",
    "        self.td = np.zeros(self.v.shape) # total derivative, used to descent\n",
    "        self.ltd = None # last total derivative\n",
    "        self.m = np.zeros(self.v.shape) # moving array\n",
    "        self.cs = cs_initial*np.ones(self.v.shape) # component-wise step\n",
    "        self.work = np.ones(self.v.shape) # working components, defult to be fully connected\n",
    "    \n",
    "    def assign_values(self, values, cs_initial=0.1):\n",
    "        self.v = np.array(values)\n",
    "        self.td = np.zeros(self.v.shape)\n",
    "        self.ltd = None\n",
    "        self.m = np.zeros(self.v.shape)\n",
    "        self.cs = cs_initial*np.ones(self.v.shape)\n",
    "        self.work = np.ones(self.v.shape)\n",
    "    \n",
    "    def derivative_assign(self, values):\n",
    "        if values.shape != self.td.shape:\n",
    "            raise ValueError(\"values shape error\")\n",
    "        \n",
    "        self.ltd = np.array(self.td)\n",
    "        self.td = np.array(values)\n",
    "    \n",
    "    def add_row(self, new_row, cs_initial=0.1):\n",
    "        self.v = np.append(self.v, np.array([new_row]), axis = 0)\n",
    "        self.td = np.append(self.td, np.zeros((1,)+new_row.shape), axis = 0)\n",
    "        self.ltd = None\n",
    "        self.m = np.zeros(self.v.shape)\n",
    "        self.cs = np.append(self.cs, cs_initial*np.ones((1,)+new_row.shape), axis = 0)\n",
    "        self.work = np.ones(self.v.shape)\n",
    "    \n",
    "    def add_column(self, new_column, cs_initial=0.1):\n",
    "        self.v = np.append(self.v, np.array([new_column]).T, axis = 1)\n",
    "        self.td = np.append(self.td, np.zeros(new_column.shape + (1,)), axis = 1)\n",
    "        self.ltd = None\n",
    "        self.m = np.zeros(self.v.shape)\n",
    "        self.cs = np.append(self.cs, cs_initial*np.ones(new_column.shape + (1,)), axis = 1)\n",
    "        self.work = np.ones(self.v.shape)\n",
    "    \n",
    "    def max_cs(self):\n",
    "        return self.cs.max()\n",
    "    \n",
    "    def reset_cs(self, new_cs):\n",
    "        self.cs = new_cs*np.ones(self.cs.shape)\n",
    "    \n",
    "    def descent(self, step = 1., descent_method = \"normal\", regularizer = (\"None\",), td_max = 0.1, move_max=1., move_min=0.000001):\n",
    "        if regularizer[0] == \"r_square\":\n",
    "            self.td += regularizer[1] * self.v\n",
    "        \n",
    "        if regularizer[0] == \"rs_extend\":\n",
    "            self.td += regularizer[1] * ((self.v>regularizer[2])*(self.v-regularizer[2]) + (self.v < -regularizer[2])*(self.v+regularizer[2]))\n",
    "        \n",
    "        if descent_method == \"normal\":\n",
    "            self.m = self.td * (np.abs(self.td) < td_max) + array_sign(self.td)*(np.abs(self.td) >= td_max)\n",
    "            self.v -= step * self.m * self.work\n",
    "        elif descent_method == \"Rprop\":\n",
    "            self.m = array_sign(self.td)\n",
    "            self.cs *= 1.2*(self.td*self.ltd>0) + 1.*(self.td*self.ltd==0) + 0.5*(self.td*self.ltd<0)\n",
    "            self.cs = self.cs * (self.cs < move_max) * (self.cs > move_min)+ move_max*(self.cs >= move_max) + move_min*(self.cs <= move_min)\n",
    "            self.v -= self.cs * self.m * self.work\n",
    "        elif descent_method == \"Dogiko Rprop\":\n",
    "            self.m = array_sign(self.td)\n",
    "            step_change = 1.2*(self.td*self.ltd>0.) + 1.*(self.td*self.ltd==0.) + 1.*(self.td==self.ltd)\n",
    "            step_change[step_change == 0.] = self.td[step_change == 0.]/(self.ltd-self.td)[step_change == 0.]\n",
    "            step_change[step_change < 0.1] = 0.1\n",
    "            self.cs *= step_change\n",
    "            self.cs = self.cs * (self.cs < move_max) * (self.cs > move_min)+ move_max*(self.cs >= move_max) + move_min*(self.cs <= move_min)\n",
    "            self.v -= self.cs * self.m * self.work\n",
    "\n",
    "# Activation functions defined start\n",
    "\n",
    "class Identity():\n",
    "    def trans(self, x):\n",
    "        return x\n",
    "    \n",
    "    def diff(self, x):\n",
    "        return np.ones(x.shape, dtype = np.float64)\n",
    "    \n",
    "    def backward(self, x,_input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class Sigmoid():\n",
    "    def trans(self, x):\n",
    "        return expit(x)\n",
    "    \n",
    "    def diff(self, x):\n",
    "        return expit(x)*expit(-x)\n",
    "    \n",
    "    def backward(self, x,_input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class Hypertan():\n",
    "    def trans(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def diff(self, x):\n",
    "        x[(x<-100)&(x>100)] = 100 # cut value out of [-100, 100] to 100, cosh(-100) = cosh(100)\n",
    "        return 1. / np.square(np.cosh(x))\n",
    "    \n",
    "    def backward(self, x,_input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class SoftSign():\n",
    "    def trans(self, x):\n",
    "        return array_sign(x)*(1. - 1./(np.abs(x) + 1.))\n",
    "    \n",
    "    def diff(self, x):\n",
    "        return 1. / np.square(np.abs(x) + 1.)\n",
    "    \n",
    "    def backward(self, x,_input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class Relu():\n",
    "    def trans(self, x):\n",
    "        return x*(x>0)\n",
    "    \n",
    "    def diff(self, x):\n",
    "        return 1.*(x>0)\n",
    "    \n",
    "    def backward(self, x, _input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class LeakyRelu():\n",
    "    def __init__(self, alpha = 0.1):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def trans(self, x):\n",
    "        return x*(x>0) + self.alpha*x*(x<0)\n",
    "    \n",
    "    def diff(self, x):\n",
    "        return 1.*(x>0) + self.alpha*(x<0)\n",
    "    \n",
    "    def backward(self, x,_input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class SoftPlus():\n",
    "    def trans(self, x):\n",
    "        return np.log(1. + np.exp(x))\n",
    "    \n",
    "    def diff(self, x):\n",
    "        return expit(x)\n",
    "    \n",
    "    def backward(self, x,_input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class Selu():\n",
    "    def __init__(self):\n",
    "        self.ahpha = 1.05071\n",
    "        self.beta = 1.67326\n",
    "    \n",
    "    def trans(self, x):\n",
    "        return self.ahpha*(x*(x>=0) + self.beta*(np.exp(x) - 1)*(x<0))\n",
    "    \n",
    "    def diff(self, x):\n",
    "        return self.ahpha*(1.*(x>=0) + self.beta*np.exp(x)*(x<0))\n",
    "    \n",
    "    def backward(self, x,_input):\n",
    "        return self.diff(x)*_input\n",
    "\n",
    "class Softmax():\n",
    "    def trans(self, x):\n",
    "        output = x - x.max(axis=0)\n",
    "        output = np.exp(output)\n",
    "        output /= output.sum(axis=0)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, x, _input):\n",
    "        tr = self.trans(x) # result of self.trans\n",
    "        return tr*_input - tr*((tr*_input).sum(axis=0))\n",
    "\n",
    "# Activation functions defined end\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, neuron_n, activation_function):\n",
    "        if type(activation_function) == type:\n",
    "            raise TypeError(\"activation_function should be a class. eg: Use 'Sigmoid()', not 'Sigmoid'\")\n",
    "        \n",
    "        self.nn = neuron_n\n",
    "        self.af = activation_function\n",
    "        self.w = VariableArray((self.nn, 0)) # linear weights working before active function\n",
    "        self.b = VariableArray((self.nn, 1)) # bias working before active function\n",
    "        self.x = np.zeros((0, self.nn))\n",
    "        self.y = np.zeros((0, self.nn))\n",
    "    \n",
    "    def forward(self, _input):\n",
    "        self.x = np.dot(self.w.v, _input) + self.b.v\n",
    "        self.y = self.af.trans(self.x)\n",
    "    \n",
    "    def backward(self, _input, source):\n",
    "        derivative = self.af.backward(self.x, _input)\n",
    "        self.w.derivative_assign(np.dot(derivative, source.T))\n",
    "        self.b.derivative_assign(np.sum(derivative, axis=1).reshape(derivative.shape[0], 1))\n",
    "        derivative = np.dot(derivative.T, self.w.v)\n",
    "        return derivative.T\n",
    "    \n",
    "    def descent(self, step, descent_method, regularizer):\n",
    "        self.w.descent(step, descent_method, regularizer)\n",
    "        self.b.descent(step, descent_method, regularizer)\n",
    "    \n",
    "    def reset_cs(self, new_cs):\n",
    "        self.w.reset_cs(new_cs)\n",
    "        self.b.reset_cs(new_cs)\n",
    "    \n",
    "    def dimension(self):\n",
    "        return self.w.v.size + self.b.v.size\n",
    "\n",
    "class DogikoLearn():\n",
    "    def __init__(self, loss_function = \"r2\"):\n",
    "        self.lf = loss_function # loss function type\n",
    "        self.ly = [] # layers list\n",
    "        self.rg = (\"None\",) # Regularizetion method\n",
    "        self.csi = 0.1 # initial component-wise step when claim new weights and bias\n",
    "    \n",
    "    def r_square_regularizer(self, alpha):\n",
    "        # Assign regularization method as radius square\n",
    "        # i.e Error += alpha*0.5*sum(weight**2) when descent\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"Input should be positive\")\n",
    "        \n",
    "        self.rg = (\"r_square\", alpha)\n",
    "    \n",
    "    def rs_extend_regularizer(self, alpha, beta):\n",
    "        # Assign regularization method as radius square\n",
    "        # i.e Error += alpha*0.5sum(weight**2) when descent\n",
    "        if (alpha <= 0) or (alpha <= 0):\n",
    "            raise ValueError(\"All input should be positive\")\n",
    "        \n",
    "        self.rg = (\"rs_extend\", alpha, beta)\n",
    "    \n",
    "    def set_training_data(self, training_input, training_labels):\n",
    "        self.tx = np.array(training_input) # training data input\n",
    "        self.ty = np.array(training_labels) # training data lables(answers)\n",
    "        if self.tx.shape[0] != self.ty.shape[0]:\n",
    "            temp_min = min(self.tx.shape[0], self.ty.shape[0])\n",
    "            self.tx = self.tx[:temp_min]\n",
    "            self.ty = self.ty[:temp_min]\n",
    "            print(\"training data #input != #output, took the minimun size automatically\")\n",
    "        \n",
    "        self.xs = self.tx.shape[1] # size of each datum input\n",
    "        self.ys = self.ty.shape[1] # size of each datum output\n",
    "    \n",
    "    def set_validation_data(self, validation_input, validation_labels):\n",
    "        self.vx = np.array(validation_input) # validation data input\n",
    "        self.vy = np.array(validation_labels) # validation data lables(answers)\n",
    "        if self.vx.shape[1] != self.xs:\n",
    "            raise ValueError(\"validation data input size should be equal to training data\")\n",
    "        \n",
    "        if self.vy.shape[1] != self.ys:\n",
    "            raise ValueError(\"validation data lables size should be equal to training data\")\n",
    "    \n",
    "    def add_layer(self, new_layer):\n",
    "        if type(new_layer) != Layer:\n",
    "            raise TypeError(\"new_layer should be a Layer (class). eg: 'Layer(30, Sigmoid())'\")\n",
    "        \n",
    "        self.ly.append(new_layer)\n",
    "    \n",
    "    def build(self):\n",
    "        self.ln = len(self.ly) # amount of layers\n",
    "        self.ly[0].w.assign_values(np.random.normal(0., 1., (self.ly[0].nn, self.xs)), self.csi)\n",
    "        self.ly[0].b.assign_values(np.random.normal(0., 1., (self.ly[0].nn, 1)), self.csi)\n",
    "        for l in range(1,self.ln):\n",
    "            self.ly[l].w.assign_values(np.random.normal(0., 1., (self.ly[l].nn, self.ly[l-1].nn)), self.csi)\n",
    "            self.ly[l].b.assign_values(np.random.normal(0., 1., (self.ly[l].nn, 1)), self.csi)\n",
    "        \n",
    "        if self.ly[-1].nn != self.ys: # cheak output size\n",
    "            raise ValueError(\"output layer must has the same size with datum lables(answer)\")\n",
    "    \n",
    "    def prediction(self, data_input):\n",
    "        self.px = np.array(data_input) # prediction data input of last time predic\n",
    "        if self.px.shape[1] != self.xs:\n",
    "            raise ValueError(\"datum size error\")\n",
    "        \n",
    "        self.ly[0].forward(self.px.T)\n",
    "        for l in range(1,self.ln):\n",
    "            self.ly[l].forward(self.ly[l-1].y)\n",
    "        \n",
    "        self.py = np.array(self.ly[-1].y.T) # prediction result of last time predict\n",
    "        \n",
    "        return self.py\n",
    "    \n",
    "    def descent(self, step = 1., descent_method = \"normal\"):\n",
    "        for l in range(self.ln):\n",
    "            self.ly[l].descent(step, descent_method, self.rg)\n",
    "        \n",
    "        if descent_method in [\"Rprop\", \"Dogiko Rprop\"]:\n",
    "            self.max_cs = 0.\n",
    "            for l in range(self.ln):\n",
    "                self.max_cs = max(self.max_cs, self.ly[l].w.max_cs(), self.ly[l].b.max_cs())\n",
    "    \n",
    "    def evaluate(self, _input, labels):\n",
    "        self.prediction(_input)\n",
    "        if self.lf == \"r2\":\n",
    "            return np.square(self.py - labels).mean()/labels.var(axis=0).mean()\n",
    "        elif self.lf == \"ce\":\n",
    "            return (-1*labels*np.log(self.py+0.0001)).sum(axis=1).mean()\n",
    "        else:\n",
    "            raise ValueError(\"loss function should be 'r2' or 'ce'\")\n",
    "    \n",
    "    def gradient_get(self, _input, labels):\n",
    "        self.prediction(_input)\n",
    "        if self.lf == \"r2\":\n",
    "            temp_derivative = 2*(self.py - labels).T/(labels.shape[0]*labels.var(axis=0).sum())\n",
    "        elif self.lf == \"ce\":\n",
    "            temp_derivative = -1*(labels/(self.py + 0.0001)).T/labels.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"loss function should be 'r2' or 'ce'\")\n",
    "        \n",
    "        for l in range(self.ln-1, 0, -1):\n",
    "            temp_derivative = self.ly[l].backward(temp_derivative, self.ly[l-1].y)\n",
    "        \n",
    "        self.ly[0].backward(temp_derivative, _input.T)\n",
    "    \n",
    "    def batch_fit(self, batch_input, batch_labels, step = 1., descent_method = \"normal\"):\n",
    "        self.gradient_get(batch_input, batch_labels)\n",
    "        self.descent(step, descent_method)\n",
    "    \n",
    "    def epoch_fit(self, batch_size = None, step = 1., descent_method = \"normal\"):\n",
    "        if type(batch_size) == type(None):\n",
    "            self.batch_fit(self.tx, self.ty, step, descent_method)\n",
    "        elif type(batch_size) == int:\n",
    "            if batch_size > 0:\n",
    "                for b in range(np.ceil(self.tx.shape[0]/ batch_size).astype(np.int)):\n",
    "                    self.batch_fit(self.tx[b*batch_size: (b+1)*batch_size],\n",
    "                                   self.ty[b*batch_size: (b+1)*batch_size],\n",
    "                                   step,\n",
    "                                   descent_method\n",
    "                                  )\n",
    "            else:\n",
    "                raise ValueError(\"batch_size should be positive int\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"batch_size should be positive int\")\n",
    "    \n",
    "    def train(self, times, batch_size = None, step = 1., descent_method = \"normal\", termination = [0,0,0.]):\n",
    "        is_termination = False\n",
    "        try:\n",
    "            termination[2] > 12345 # test whether threshold is an real number (no mater int, float,.etc)\n",
    "            termination[0] = int(termination[0])\n",
    "            termination[1] = int(termination[1])\n",
    "            if (termination[0] < termination[1]) and (termination[0] > 0):\n",
    "                is_termination = True\n",
    "                error_record = []\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for t in range(times):\n",
    "            self.epoch_fit(batch_size, step, descent_method)\n",
    "            if is_termination:\n",
    "                if self.lf == \"ce\":\n",
    "                    error_record.append(10*np.log10(1.000000001 - self.validation_accuracy()))\n",
    "                else:\n",
    "                    error_record.append(10*np.log10(self.validation_error()+0.000000001))\n",
    "                # 0.000000001, bias for prevent error when log(0)\n",
    "                \n",
    "                if t >= (termination[1] - 1):\n",
    "                    short_mean = sum(error_record[(-termination[0]):])/termination[0]\n",
    "                    long_mean = sum(error_record[(-termination[1]):])/termination[1]\n",
    "                    if (long_mean - short_mean) < termination[2]:\n",
    "                        return t+1\n",
    "        \n",
    "        return times\n",
    "            \n",
    "    def accuracy(self, inference, target):\n",
    "        if inference.shape != target.shape:\n",
    "            raise ValueError(\"shape of inference and target non-equal\")\n",
    "            \n",
    "        return (inference.argmax(axis=1) == target.argmax(axis=1)).sum()/inference.shape[0]\n",
    "    \n",
    "    def training_error(self):\n",
    "        return self.evaluate(self.tx, self.ty)\n",
    "    \n",
    "    def training_accuracy(self):\n",
    "        return self.accuracy(self.prediction(self.tx), self.ty)\n",
    "    \n",
    "    def validation_error(self):\n",
    "        return self.evaluate(self.vx, self.vy)\n",
    "    \n",
    "    def validation_accuracy(self):\n",
    "        return self.accuracy(self.prediction(self.vx), self.vy)\n",
    "    \n",
    "    def neuron_refined(self, l, reference_data = None, threshold = 0.01):\n",
    "        # l : the # of layer\n",
    "        # threshold : threshold for information contained of dimension be remaind\n",
    "        if type(l) != int:\n",
    "            raise TypeError(\"l should be the layer no. of hidden layer, an int between 0 to (neural_number - 2)\")\n",
    "        elif (l >= self.ln - 1) or (l < 0):\n",
    "            raise ValueError(\"l should be the layer no. of hidden layer, an int between 0 to (neural_number - 2)\")\n",
    "        \n",
    "        try:\n",
    "            if ((threshold< 1) and (threshold>0)) or (type(threshold) == int):\n",
    "                if (threshold > self.ly[l].nn-1):\n",
    "                    raise ValueError(\"int threshold error : removed #neuron should less than currently #neuron\")\n",
    "                elif (threshold < -self.ly[l].nn) or (threshold==0):\n",
    "                    return None\n",
    "                    # do nothing if remove no #neuron (threshold=0) or want to remain #neuron more than currently\n",
    "            else:\n",
    "                raise ValueError(\"threshold : a value in (0, 1), or an nonzero int\")\n",
    "        except:\n",
    "            raise ValueError(\"threshold : a value in (0, 1), or an nonzero int\")\n",
    "        \n",
    "        if type(reference_data) == type(None):\n",
    "            self.prediction(self.tx)\n",
    "        else:\n",
    "            self.prediction(reference_data)\n",
    "        \n",
    "        ym = self.ly[l].y.mean(axis=1).reshape((self.ly[l].nn,1)) # y (output of Layer) mean of each neurons\n",
    "        yn = self.ly[l].y - ym # centralized y\n",
    "        ab = np.dot(self.ly[l+1].w.v, ym) # Adjusted bias\n",
    "        ev, em = np.linalg.eigh(np.dot(yn, yn.T)) # eigenvalues and eigenmatrix(with eigenvectors as columns)\n",
    "        ir = ev/ev.sum() # info ratio for each eigenvector\n",
    "        # op, pv :column operator result and pivots\n",
    "        if (threshold< 1) and (threshold>0):\n",
    "            op, pv = column_operate(em[:,ir > threshold])\n",
    "        else:\n",
    "            op, pv = column_operate(em[:,ir >= ir[ir.argsort()[threshold]]])\n",
    "            \n",
    "        nw = np.dot(self.ly[l+1].w.v, op) # new weight\n",
    "        self.ly[l+1].b.assign_values(self.ly[l+1].b.v + (np.dot(self.ly[l+1].w.v, ym) -np.dot(nw, ym[pv])))\n",
    "        self.ly[l+1].w.assign_values(nw) # l+1 weight should be rewrite after l+1 bias have been rewrite\n",
    "        self.ly[l].w.assign_values(self.ly[l].w.v[pv])\n",
    "        self.ly[l].b.assign_values(self.ly[l].b.v[pv])\n",
    "        self.ly[l].nn = len(pv)\n",
    "    \n",
    "    def neuron_proliferate(self, proliferating_layer, proliferating_n = 1, output_weight_bound = 1.):\n",
    "        if proliferating_layer not in range(self.ln):\n",
    "            raise ValueError(\"proliferating_layer should be an int from 0 to (#layer-1)\")\n",
    "            \n",
    "        if type(proliferating_n) != int:\n",
    "            raise ValueError(\"proliferating_n should be int\")\n",
    "        \n",
    "        if proliferating_n <= 0:\n",
    "            raise ValueError(\"proliferating_n should be postive\")\n",
    "            \n",
    "        if output_weight_bound < 0.:\n",
    "            raise ValueError(\"output_weight_bound should be non-negative\")\n",
    "            \n",
    "        l = proliferating_layer\n",
    "        for t in range(proliferating_n):\n",
    "            self.ly[l].w.add_row(mcmc_normal(self.ly[l].w.v, mean=self.ly[l].w.v.mean(), std=self.ly[l].w.v.std()))\n",
    "            self.ly[l].b.add_row(mcmc_normal(self.ly[l].b.v, mean=self.ly[l].b.v.mean(), std=self.ly[l].b.v.std()))\n",
    "            self.ly[l+1].w.add_column(output_weight_bound*(2*np.random.rand((self.ly[l+1].nn))-1.))\n",
    "            self.ly[l].nn += 1\n",
    "    \n",
    "    def reset_cs(self, new_cs):\n",
    "        for l in range(self.ln):\n",
    "            self.ly[l].reset_cs(new_cs)\n",
    "    \n",
    "    def inter_layer_linear_regression(self, layer_interval):\n",
    "        try:\n",
    "            ls = layer_interval[0] # layer start\n",
    "            le = layer_interval[1] # layer end\n",
    "            if (ls < le) and (ls >= 0) and (le < self.ln):\n",
    "                if ls == 0:\n",
    "                    ri = np.array(self.px.T) # regression input\n",
    "                else:\n",
    "                    ri = np.array(self.ly[ls-1].y)\n",
    "                \n",
    "                ri = np.append(ri, np.ones((1, ri.shape[1])), axis=0) # append 1. for each datum as bias\n",
    "                ro = np.array(self.ly[le].x)\n",
    "            else:\n",
    "                raise ValueError(\"layer_interval should be list-like, two int (a, b), with 0 <= a < b < total layer\")\n",
    "        \n",
    "        except:\n",
    "            raise ValueError(\"layer_interval should be list-like, two int (a, b), with 0 <= a < b < total layer\")\n",
    "        \n",
    "        rr = np.linalg.lstsq(ri.T, ro.T) # regression result (matrix, residuals, rank of ri, singuler values of ri)\n",
    "        if len(rr[1]) == 0:\n",
    "            raise ValueError(\"output data of layer\" + str(ls-1) + \"(= -1, for input data) should be full rank, try self.nruron_refine first\")\n",
    "        \n",
    "        return rr[0], rr[1]/ri.shape[1]\n",
    "    \n",
    "    def find_linearist_layers(self, reference_data = None):\n",
    "        output = (0, 0, np.inf, np.array([[]]), np.zeros((0,0)))\n",
    "        if type(reference_data) == type(None):\n",
    "            self.prediction(self.tx)\n",
    "        else:\n",
    "            self.prediction(reference_data)\n",
    "        \n",
    "        for l1 in range(self.ln-1):\n",
    "            for l2 in range(i+1, self.ln):\n",
    "                rr = self.inter_layer_linear_regression((l1,l2))\n",
    "                if np.sqrt(rr[1].sum()) < output[2]:\n",
    "                    output = (l1, l2, np.sqrt(rr[1].sum()), rr[0])\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def layer_filled(self, layer_interval, weights, bias):\n",
    "        try:\n",
    "            ls = layer_interval[0] # layer start\n",
    "            le = layer_interval[1] # layer end\n",
    "            if (ls < le) and (ls >= 0) and (le < self.ln):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\"layer_interval should be list-like, two int (a, b), with 0 <= a < b < total layer\")\n",
    "        except:\n",
    "            raise ValueError(\"layer_interval should be list-like, two int (a, b), with 0 <= a < b < total layer\")\n",
    "        \n",
    "        if weights.shape[0] != bias.shape[0]:\n",
    "            raise ValueError(\"weights.shape[0] doesn't match bias.shape[0]\")\n",
    "        \n",
    "        if weights.shape[0] != self.ly[le].nn:\n",
    "            raise ValueError(\"weights.shape[0] doesn't match #neuron of layer at end of layer_interval\")\n",
    "        \n",
    "        self.ly[le].w.assign_values(weights)\n",
    "        self.ly[le].b.assign_values(bias)\n",
    "        self.ly = self.ly[:ls] + self.ly[le:]\n",
    "        self.ln = len(self.ly)\n",
    "    \n",
    "    def linear_filled(self, layer_interval):\n",
    "        try:\n",
    "            ls = layer_interval[0] # layer start\n",
    "            le = layer_interval[1] # layer end\n",
    "            if (ls < le) and (ls >= 0) and (le < self.ln):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\"layer_interval should be list-like, two int (a, b), with 0 <= a < b < total layer\")\n",
    "        except:\n",
    "            raise ValueError(\"layer_interval should be list-like, two int (a, b), with 0 <= a < b < total layer\")\n",
    "            \n",
    "        rr = self.inter_layer_linear_regression(layer_interval)\n",
    "        self.layer_filled(layer_interval, rr[0].T[:,:-1], rr[0].T[:,-1:])\n",
    "    \n",
    "    def insert_layer(self, position, weights, bias, activation_function, next_layer_weights, next_layer_bias):\n",
    "        if type(position) == int:\n",
    "            if position in range(self.ln):\n",
    "                pass\n",
    "        else:\n",
    "            raise ValueError(\"position should be int between 0 to self.ln\")\n",
    "        \n",
    "        if type(activation_function) == type:\n",
    "            raise TypeError(\"activation_function should be a class. eg: Use 'Sigmoid()', not 'Sigmoid'\")\n",
    "        \n",
    "        ilo, ili = weights.shape # input and output size of inserted layer\n",
    "        nlo, nli = next_layer_weights.shape # input and output size of next layer\n",
    "        \n",
    "        if position == 0:\n",
    "            if ili != self.xs:\n",
    "                raise ValueError(\"weights.shape error, cheak input and output size for this new layer\")\n",
    "        else:\n",
    "            if ili != self.ly[position-1].nn:\n",
    "                raise ValueError(\"weights.shape error, cheak input and output size for this new layer\")\n",
    "        \n",
    "        if (ilo != bias.shape[0]) or (ilo != nli):\n",
    "            raise ValueError(\"to define #neuron of new layer, all related weighs and bias size should be consistent\")\n",
    "        \n",
    "        if nlo != self.ly[position].nn:\n",
    "            raise ValueError(\"next_layer_weights.shape error, cheak #neuron of next layer\")\n",
    "        \n",
    "        if next_layer_bias.shape[0] != self.ly[position].nn:\n",
    "            raise ValueError(\"next_layer_bias.shape error, cheak #neuron of next layer\")\n",
    "        \n",
    "        if (bias.shape[1] != 1) or (next_layer_bias.shape[1] != 1):\n",
    "            raise ValueError(\"bias shape should be (#neuron, 1)\")\n",
    "        \n",
    "        l = position\n",
    "        \n",
    "        self.ly.insert(l, Layer(ilo, activation_function))\n",
    "        self.ly[l].w.assign_values(weights)\n",
    "        self.ly[l].b.assign_values(bias)\n",
    "        self.ly[l+1].w.assign_values(next_layer_weights)\n",
    "        self.ly[l+1].b.assign_values(next_layer_bias)\n",
    "        \n",
    "        self.ln = len(self.ly)\n",
    "    \n",
    "    def identity_dig(self, position, activation_function):\n",
    "        if type(position) == int:\n",
    "            if position in range(self.ln):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\"position should be int between 0 to self.ln\")\n",
    "        else:\n",
    "            raise ValueError(\"position should be int between 0 to self.ln\")\n",
    "        \n",
    "        if type(activation_function) == type:\n",
    "            raise TypeError(\"activation_function should be a class. eg: Use 'Sigmoid()', not 'Sigmoid'\")\n",
    "        \n",
    "        l = position\n",
    "        # ids : size of identity transform, input size of new layer\n",
    "        if l == 0:\n",
    "            ids = self.xs\n",
    "        else:\n",
    "            ids = self.ly[l-1].nn\n",
    "        \n",
    "        if type(activation_function) in [Relu, SoftPlus]:\n",
    "            liw = np.concatenate((np.identity(ids), -np.identity(ids)), axis = 0)\n",
    "            lib = np.zeros((2*ids, 1))\n",
    "            low = np.concatenate((np.identity(ids), -np.identity(ids)), axis = 1)\n",
    "            lob = np.zeros((ids, 1))\n",
    "        elif type(activation_function) == LeakyRelu:\n",
    "            liw = np.concatenate((np.identity(ids), -np.identity(ids)), axis = 0)\n",
    "            lib = np.zeros((2*ids, 1))\n",
    "            low = np.concatenate((np.identity(ids), -np.identity(ids)), axis = 1) / (1.+activation_function.alpha)\n",
    "            lob = np.zeros((ids, 1))\n",
    "        elif type(activation_function) == Identity:\n",
    "            liw = np.identity(ids)\n",
    "            lib = np.zeros((2*ids, 1))\n",
    "            low = np.identity(ids)\n",
    "            lob = np.zeros((ids, 1))\n",
    "        elif type(activation_function) in [Sigmoid, Hypertan, Selu]:\n",
    "            # li : input of new layer\n",
    "            if l == 0:\n",
    "                li = np.array(self.tx.T)\n",
    "            else:\n",
    "                li = np.array(self.ly[l-1].y)\n",
    "            \n",
    "            lim = li.mean(axis=1)\n",
    "            lis = li.std(axis=1) + 1.\n",
    "            \n",
    "            liw = np.diag(1./lis)\n",
    "            if type(activation_function) == Selu:\n",
    "                lib = 1.-(lim/lis).reshape(-1,1) # let mean become one before transform by activation function\n",
    "            else:\n",
    "                lib = -(lim/lis).reshape(-1,1) # let mean become zero before transform by activation function\n",
    "            \n",
    "            lo = activation_function.trans(np.dot(liw, li)+lib)\n",
    "            lo = np.append(lo, np.ones((1, lo.shape[1])), axis=0) # append 1. for each datum as bias\n",
    "            rr = np.linalg.lstsq(lo.T, li.T) # regression result (matrix, residuals, rank of ri, singuler values of ri)\n",
    "            # since the goal is construct identity, try to find linear transform form layer output to layer input\n",
    "            low = rr[0].T[:,:-1]\n",
    "            lob = rr[0].T[:,-1:]\n",
    "        else:\n",
    "            raise TypeError(\"activation_function type error\")\n",
    "        \n",
    "        nlw = np.dot(self.ly[l].w.v, low)\n",
    "        nlb = np.dot(self.ly[l].w.v, lob) + self.ly[l].b.v\n",
    "        \n",
    "        self.insert_layer(l,\n",
    "                          liw,\n",
    "                          lib,\n",
    "                          activation_function,\n",
    "                          nlw,\n",
    "                          nlb\n",
    "                         )\n",
    "    \n",
    "    def dimension(self):\n",
    "        output = 0\n",
    "        for l in range(self.ln):\n",
    "            output += self.ly[l].dimension()\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def save_weight(self, dir_name):\n",
    "        for l in range(self.ln):\n",
    "            np.save(dir_name + \"/w%i.npy\" % l, self.ly[l].w.v)\n",
    "            np.save(dir_name + \"/b%i.npy\" % l, self.ly[l].b.v)\n",
    "    \n",
    "    def load_weight(self, dir_name):\n",
    "        for l in range(self.ln):\n",
    "            try:\n",
    "                if l == 0:\n",
    "                    if np.load(dir_name + \"/w%i.npy\" % l).shape[1] != self.xs:\n",
    "                        raise ValueError(\"layer %i input size error, cheak weight size.\" % l)\n",
    "                else:\n",
    "                    if np.load(dir_name + \"/w%i.npy\" % l).shape[1] != self.ly[l-1].nn:\n",
    "                        raise ValueError(\"layer %i input size error, cheak weight size.\" % l)\n",
    "\n",
    "                if np.load(dir_name + \"/w%i.npy\" % l).shape[0] != self.ly[l].nn:\n",
    "                    raise ValueError(\"layer %i neuron size error, cheak weight size.\" % l)\n",
    "\n",
    "                if np.load(dir_name + \"/b%i.npy\" % l).shape[0] != self.ly[l].nn:\n",
    "                    raise ValueError(\"layer %i neuron size error, cheak bias size.\" % l)\n",
    "\n",
    "                if np.load(dir_name + \"/b%i.npy\" % l).shape[1] != 1:\n",
    "                    raise ValueError(\"layer %i bias size error, should be 1.\" % l)\n",
    "            \n",
    "            except:\n",
    "                raise ValueError(\"load .npy error, cheak dir.\")\n",
    "            \n",
    "            self.ly[l].w.assign_values(np.load(dir_name + \"/w%i.npy\" % l))\n",
    "            self.ly[l].b.assign_values(np.load(dir_name + \"/b%i.npy\" % l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient cheak : case regression\n",
    "\n",
    "For the regression case, using r2 error\n",
    "\n",
    "Cheak backward propagation by computing difference between gradient got from backward propagation and numerical method\n",
    "\n",
    "The difference may become large when r2 error large by this property\n",
    "\n",
    "$$\\frac{\\partial}{\\partial x} x^2 = 2x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.normal(0.,1., (1000,2))\n",
    "Y = np.sqrt((X**2).sum(axis=1)).reshape(-1,1)\n",
    "\n",
    "NN = DogikoLearn(loss_function=\"r2\")\n",
    "NN.set_training_data(X, Y)\n",
    "NN.set_validation_data(X, Y)\n",
    "NN.add_layer(Layer(4, Identity()))\n",
    "NN.add_layer(Layer(4, Sigmoid()))\n",
    "NN.add_layer(Layer(4, Hypertan()))\n",
    "NN.add_layer(Layer(4, SoftSign()))\n",
    "NN.add_layer(Layer(4, Relu()))\n",
    "NN.add_layer(Layer(4, LeakyRelu()))\n",
    "NN.add_layer(Layer(4, SoftPlus()))\n",
    "NN.add_layer(Layer(4, Selu()))\n",
    "NN.add_layer(Layer(1, Identity()))\n",
    "NN.build()\n",
    "\n",
    "threshold = 10**(-4)\n",
    "epsilon = 10**(-8)\n",
    "\n",
    "for l in range(NN.ln):\n",
    "    for wi in range(NN.ly[l].w.v.shape[0]):\n",
    "        for wj in range(NN.ly[l].w.v.shape[1]):\n",
    "            NN.build() # reset weights randomly\n",
    "            NN.gradient_get(X,Y)\n",
    "            pd = NN.ly[l].w.td[wi][wj] # partial derivative by backward propagation\n",
    "            ea = NN.evaluate(X,Y) # error before slightly moving\n",
    "            NN.ly[l].w.v[wi][wj] += epsilon # slightly moving\n",
    "            eb = NN.evaluate(X,Y) # error after slightly moving\n",
    "            if (pd - (eb-ea)/epsilon) > threshold: # if difference large (than threshold), print.\n",
    "                print(pd - ((eb-ea)/epsilon), NN.evaluate(X,Y))\n",
    "            \n",
    "    for bi in range(NN.ly[l].b.v.shape[0]): # bias part\n",
    "        NN.build()\n",
    "        NN.gradient_get(X,Y)\n",
    "        pd = NN.ly[l].b.td[bi][0]\n",
    "        ea = NN.evaluate(X,Y)\n",
    "        NN.ly[l].b.v[bi][0] += epsilon\n",
    "        eb = NN.evaluate(X,Y)\n",
    "        if (pd - (eb-ea)/epsilon) > threshold:\n",
    "            print(pd - ((eb-ea)/epsilon), NN.evaluate(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient cheak : case classification\n",
    "\n",
    "For the case classification, using cross entropy\n",
    "\n",
    "Cheak backward propagation by computing difference between gradient got from backward propagation and numerical method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.normal(0.,1., (1000,2))\n",
    "Y = np.zeros((1000,2))\n",
    "Y[:,0] = (1.*np.sqrt((X**2).sum(axis=1)) > 1.)\n",
    "Y[:,1] = 1. - Y[:,0]\n",
    "\n",
    "NN = DogikoLearn(loss_function=\"ce\")\n",
    "NN.set_training_data(X, Y)\n",
    "NN.set_validation_data(X, Y)\n",
    "NN.add_layer(Layer(4, Identity()))\n",
    "NN.add_layer(Layer(4, Sigmoid()))\n",
    "NN.add_layer(Layer(4, Hypertan()))\n",
    "NN.add_layer(Layer(4, SoftSign()))\n",
    "NN.add_layer(Layer(4, Relu()))\n",
    "NN.add_layer(Layer(4, LeakyRelu()))\n",
    "NN.add_layer(Layer(4, SoftPlus()))\n",
    "NN.add_layer(Layer(4, Selu()))\n",
    "NN.add_layer(Layer(2, Softmax()))\n",
    "NN.build()\n",
    "\n",
    "threshold = 10**(-4)\n",
    "epsilon = 10**(-8)\n",
    "\n",
    "for l in range(NN.ln):\n",
    "    for wi in range(NN.ly[l].w.v.shape[0]):\n",
    "        for wj in range(NN.ly[l].w.v.shape[1]):\n",
    "            NN.build() # reset weights randomly\n",
    "            NN.gradient_get(X,Y)\n",
    "            pd = NN.ly[l].w.td[wi][wj] # partial derivative by backward propagation\n",
    "            ea = NN.evaluate(X,Y) # error before slightly moving\n",
    "            NN.ly[l].w.v[wi][wj] += epsilon # slightly moving\n",
    "            eb = NN.evaluate(X,Y) # error after slightly moving\n",
    "            if (pd - (eb-ea)/epsilon) > threshold: # if difference large (than threshold), print.\n",
    "                print(pd - ((eb-ea)/epsilon), NN.evaluate(X,Y))\n",
    "    \n",
    "    for bi in range(NN.ly[l].b.v.shape[0]): # bias part\n",
    "        NN.build()\n",
    "        NN.gradient_get(X,Y)\n",
    "        pd = NN.ly[l].b.td[bi][0]\n",
    "        ea = NN.evaluate(X,Y)\n",
    "        NN.ly[l].b.v[bi][0] += epsilon\n",
    "        eb = NN.evaluate(X,Y)\n",
    "        if (pd - (eb-ea)/epsilon) > threshold:\n",
    "            print(pd - ((eb-ea)/epsilon), NN.evaluate(X,Y))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "\n",
    "Fit $y = \\sin{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = (np.arange(201)/50) - 2\n",
    "X = X.reshape((201,1))\n",
    "Y = np.sin(2*X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4i+EEAHo/wBSUZRc6DTigAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b8c3710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN = DogikoLearn()\n",
    "NN.r_square_regularizer(0.000001)\n",
    "NN.set_training_data(X, Y)\n",
    "NN.set_validation_data(X, Y)\n",
    "NN.add_layer(Layer(30, Relu()))\n",
    "NN.add_layer(Layer(1,Identity()))\n",
    "NN.build()\n",
    "\n",
    "NN.train(100, descent_method=\"Rprop\")\n",
    "\n",
    "plt.plot(X.reshape((201)), NN.py.reshape((201)), \"b\", X.reshape((201)), Y.reshape((201)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Example 2\n",
    "\n",
    "Net-shape classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAGfCAYAAAAgfbd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK/5/4bm/515tfMwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b4590f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([np.arange(81).repeat(81), np.arange(81*81) % 81]).astype(np.float64)\n",
    "X -= 40.\n",
    "X /= 40.\n",
    "Y_temp = (((X[0] + X[1] - 0.5) % 2.) > 1.) ^ (((X[0] - X[1] - 0.5) % 2.) > 1.)\n",
    "Y = np.zeros(Y_temp.shape + (2,))\n",
    "Y[:,0] = Y_temp.astype(np.float64)\n",
    "Y[:,1] = 1 - Y[:,0]\n",
    "X = X.T\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(X.T[0][Y[:,0]==1], X.T[1][Y[:,0]==1], \"bp\")\n",
    "plt.plot(X.T[0][Y[:,1]==1], X.T[1][Y[:,1]==1], \"rp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "permu = np.random.permutation(np.arange(81*81))\n",
    "\n",
    "X_train = X[permu[:5000]]\n",
    "Y_train = Y[permu[:5000]]\n",
    "X_valid = X[permu[5000:]]\n",
    "Y_valid = Y[permu[5000:]]\n",
    "\n",
    "NN = DogikoLearn(loss_function=\"ce\")\n",
    "NN.rs_extend_regularizer(0.001,3.)\n",
    "NN.set_training_data(X_train, Y_train)\n",
    "NN.set_validation_data(X_valid, Y_valid)\n",
    "NN.add_layer(Layer(10, Hypertan()))\n",
    "NN.add_layer(Layer(10, Hypertan()))\n",
    "NN.add_layer(Layer(2, Softmax()))\n",
    "NN.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "15, 15, 61\n",
      "0.053 0.071 0.977\n",
      "32\n",
      "15, 15, 86\n",
      "0.051 0.067 0.983\n",
      "52\n",
      "15, 15, 75\n",
      "0.05 0.064 0.98\n",
      "57\n",
      "15, 15, 148\n",
      "0.046 0.056 0.983\n",
      "48\n",
      "15, 15, 54\n",
      "0.05 0.066 0.976\n",
      "105\n",
      "15, 15, 70\n",
      "0.042 0.054 0.985\n",
      "31\n",
      "15, 15, 48\n",
      "0.041 0.055 0.985\n",
      "59\n",
      "15, 15, 92\n",
      "0.04 0.052 0.984\n",
      "37\n",
      "15, 15, 48\n",
      "0.04 0.055 0.98\n",
      "64\n",
      "15, 15, 59\n",
      "0.038 0.053 0.983\n",
      "81\n",
      "15, 15, 46\n",
      "0.047 0.057 0.978\n",
      "75\n",
      "15, 15, 77\n",
      "0.039 0.052 0.985\n",
      "42\n",
      "15, 15, 62\n",
      "0.038 0.049 0.986\n",
      "33\n",
      "15, 15, 62\n",
      "0.036 0.048 0.987\n",
      "92\n",
      "15, 15, 72\n",
      "0.034 0.044 0.989\n",
      "36\n",
      "15, 15, 127\n",
      "0.031 0.043 0.99\n",
      "33\n",
      "15, 15, 119\n",
      "0.031 0.046 0.987\n",
      "46\n",
      "15, 15, 61\n",
      "0.034 0.046 0.987\n",
      "34\n",
      "15, 15, 99\n",
      "0.03 0.043 0.986\n",
      "51\n",
      "15, 15, 93\n",
      "0.03 0.043 0.986\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "for t in range(20):\n",
    "    \"\"\"\n",
    "    permu = np.random.permutation(np.arange(81*81))\n",
    "    X_train = X[permu[:5000]]\n",
    "    Y_train = Y[permu[:5000]]\n",
    "    X_valid = X[permu[5000:]]\n",
    "    Y_valid = Y[permu[5000:]]\n",
    "    NN.set_training_data(X_train, Y_train)\n",
    "    NN.set_validation_data(X_valid, Y_valid)\n",
    "    \"\"\"\n",
    "    for l in range(NN.ln-1):\n",
    "        NN.neuron_proliferate(l, 1, 0.01/NN.ly[l+1].dimension())\n",
    "    \n",
    "    print(NN.train(1000, descent_method=\"Rprop\", termination=[10,30,0.]))\n",
    "    \n",
    "    #dr = NN.dimension()/NN.tx.shape[0]\n",
    "    #er = max(1., NN.validation_error()/NN.training_error())\n",
    "    \n",
    "    for l in range(NN.ln-1):\n",
    "        NN.neuron_refined(l, X_valid, -15)\n",
    "        print(NN.ly[l].nn, end=\", \")\n",
    "    \n",
    "    print(NN.train(1000, descent_method=\"Rprop\", termination=[10,30,0.]))\n",
    "    \n",
    "    print(round(NN.training_error(), 3),\n",
    "          round(NN.validation_error(), 3),\n",
    "          round((NN.prediction(NN.vx).argmax(axis=1) == NN.vy.argmax(axis=1)).sum()/NN.vy.shape[0], 3)\n",
    "         )\n",
    "\n",
    "print(\"down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99680000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.training_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044689872293273848"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.validation_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN.identity_dig(2, Hypertan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9, 16, 13, 436 0.01 0.022\n",
      "9, 17, 13, 459 0.008 0.024\n",
      "8, 15, 10, 341 0.014 0.022\n",
      "8, 16, 11, 379 0.009 0.02\n",
      "8, 17, 12, 419 0.008 0.02\n",
      "8, 18, 13, 461 0.006 0.022\n",
      "7, 13, 12, 319 0.018 0.03\n",
      "7, 14, 13, 356 0.011 0.023\n",
      "7, 15, 14, 395 0.01 0.021\n",
      "7, 16, 15, 436 0.008 0.026\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAGfCAYAAAAgfbd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuPsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106ec2b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN.train(500, descent_method=\"Rprop\")\n",
    "dr = NN.dimension()/NN.tx.shape[0]\n",
    "er = max(1., NN.validation_error()/NN.training_error())\n",
    "NN.neuron_refined(NN.ln-2, X_valid, min(1., (er**3)*(dr**3))/(NN.ly[NN.ln-2].nn))\n",
    "\n",
    "for t in range(10):\n",
    "    for l in range(NN.ln-1):\n",
    "        NN.neuron_proliferate(l, 1, 0.01/NN.ly[l+1].dimension())\n",
    "\n",
    "    NN.train(500, descent_method=\"Rprop\")\n",
    "    \n",
    "    dr = NN.dimension()/NN.tx.shape[0]\n",
    "    er = max(1., NN.validation_error()/NN.training_error())\n",
    "    \n",
    "    for l in range(NN.ln-1):\n",
    "        NN.neuron_refined(l, X_valid, min(1., (er**3)*(dr**3))/(NN.ly[l].nn))\n",
    "        print(NN.ly[l].nn, end=\", \")\n",
    "    \n",
    "    NN.train(500, descent_method=\"Rprop\")\n",
    "    \n",
    "    print(NN.dimension(), round(NN.training_error(), 3), round(NN.validation_error(), 3))\n",
    "\n",
    "NN.prediction(X_valid)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(X_valid.T[0][NN.py[:,0]>0.5], X_valid.T[1][NN.py[:,0]>0.5], \"bp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "100\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "accuracys_t = np.zeros((100))\n",
    "accuracys_v = np.zeros((100))\n",
    "for t in range(100):\n",
    "    NN = DogikoLearn(loss_function=\"ce\")\n",
    "    NN.rs_extend_regularizer(0.001,3.)\n",
    "    NN.set_training_data(X_train, Y_train)\n",
    "    NN.set_validation_data(X_valid, Y_valid)\n",
    "    NN.add_layer(Layer(10,LeakyRelu()))\n",
    "    NN.add_layer(Layer(10,LeakyRelu()))\n",
    "    NN.add_layer(Layer(2,Softmax()))\n",
    "    NN.build()\n",
    "    \n",
    "    NN.train(1000, descent_method=\"Rprop\")\n",
    "    \n",
    "    accuracys_t[t] = NN.training_error()\n",
    "    accuracys_v[t] = NN.validation_error()\n",
    "    \n",
    "    if (t+1) % 5 ==0:\n",
    "        print(t+1)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.055  0.058  0.058  0.067  0.069  0.071  0.072  0.075  0.076  0.076\n",
      "  0.077  0.079  0.079  0.079  0.08   0.08   0.081  0.081  0.082  0.083\n",
      "  0.084  0.084  0.084  0.085  0.085  0.086  0.087  0.087  0.087  0.088\n",
      "  0.088  0.088  0.089  0.089  0.089  0.09   0.09   0.09   0.091  0.092\n",
      "  0.093  0.094  0.094  0.095  0.095  0.096  0.097  0.098  0.098  0.098\n",
      "  0.099  0.099  0.099  0.101  0.102  0.102  0.102  0.103  0.103  0.104\n",
      "  0.104  0.104  0.104  0.105  0.105  0.107  0.108  0.108  0.109  0.111\n",
      "  0.112  0.113  0.115  0.118  0.119  0.119  0.12   0.12   0.125  0.127\n",
      "  0.127  0.128  0.129  0.131  0.131  0.132  0.133  0.133  0.134  0.134\n",
      "  0.137  0.137  0.138  0.141  0.149  0.174  0.206  0.327  0.384  0.441]\n",
      "0.055 0.086 0.099 0.119 0.441\n"
     ]
    }
   ],
   "source": [
    "accuracys_t.sort()\n",
    "accuracys_t = np.round(accuracys_t, 3)\n",
    "print(accuracys_t)\n",
    "print(accuracys_t.min(), accuracys_t[25], accuracys_t[50], accuracys_t[75], accuracys_t.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.057  0.061  0.063  0.071  0.071  0.072  0.074  0.078  0.078  0.078\n",
      "  0.08   0.081  0.082  0.082  0.082  0.083  0.083  0.084  0.085  0.087\n",
      "  0.087  0.087  0.088  0.088  0.088  0.088  0.089  0.089  0.089  0.09   0.09\n",
      "  0.09   0.09   0.09   0.091  0.091  0.092  0.092  0.092  0.093  0.094\n",
      "  0.094  0.095  0.098  0.098  0.098  0.098  0.098  0.099  0.101  0.101\n",
      "  0.102  0.103  0.103  0.103  0.105  0.106  0.106  0.107  0.107  0.107\n",
      "  0.108  0.108  0.108  0.109  0.109  0.111  0.112  0.113  0.114  0.116\n",
      "  0.116  0.117  0.118  0.121  0.124  0.124  0.125  0.125  0.126  0.126\n",
      "  0.132  0.132  0.133  0.135  0.135  0.135  0.138  0.139  0.139  0.139\n",
      "  0.142  0.146  0.148  0.152  0.18   0.207  0.342  0.396  0.461]\n",
      "0.057 0.088 0.101 0.124 0.461\n"
     ]
    }
   ],
   "source": [
    "accuracys_v.sort()\n",
    "accuracys_v = np.round(accuracys_v, 3)\n",
    "print(accuracys_v)\n",
    "print(accuracys_v.min(), accuracys_v[25], accuracys_v[50], accuracys_v[75], accuracys_v.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 (3, 10) 0.0789749677881\n",
      "0 2 (3, 10) 0.151427476744\n",
      "0 3 (3, 2) 0.128019887719\n",
      "1 2 (11, 10) 0.0163064692087\n",
      "1 3 (11, 2) 0.0221946229495\n",
      "2 3 (11, 2) 0.00461351269551\n"
     ]
    }
   ],
   "source": [
    "NN.validation_error()\n",
    "for i in range(NN.ln-1):\n",
    "    for j in range(i+1, NN.ln):\n",
    "        rr = NN.inter_layer_linear_regression((i,j))\n",
    "        print(i, j, rr[0].shape, (rr[1].sum()/(NN.ly[j].x.var(axis=1).sum()+0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examlple 3\n",
    "Linear case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.normal(0,1, (10000, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.random.normal(0,1, (5,5))\n",
    "while np.linalg.det(A) < 0.5:\n",
    "    A = np.random.normal(0,1, (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.dot(X,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = DogikoLearn(loss_function=\"r2\")\n",
    "NN.rs_extend_regularizer(0.001,10.)\n",
    "NN.set_training_data(X, Y)\n",
    "NN.set_validation_data(X, Y)\n",
    "NN.add_layer(Layer(50,LeakyRelu()))\n",
    "NN.add_layer(Layer(50,LeakyRelu()))\n",
    "NN.add_layer(Layer(50,LeakyRelu()))\n",
    "NN.add_layer(Layer(5,Identity()))\n",
    "NN.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9, 12, 27, 0.0493435386694\n",
      "9, 9, 12, 0.0113445106801\n",
      "10, 8, 12, 0.00755824874162\n",
      "10, 8, 10, 0.00444346400938\n",
      "10, 9, 10, 0.00263462290757\n",
      "12, 9, 10, 0.000664910727598\n",
      "9, 8, 8, 0.00237638763757\n",
      "8, 8, 7, 0.00076685471248\n",
      "7, 8, 7, 0.00224576035833\n",
      "7, 8, 8, 0.00104895855289\n",
      "7, 7, 7, 0.00155323345726\n",
      "8, 7, 7, 0.000591984296887\n",
      "7, 7, 6, 8.92301498747e-05\n",
      "6, 7, 7, 0.00106030334232\n",
      "7, 8, 7, 0.000243928801053\n",
      "7, 8, 7, 0.000579466981622\n",
      "7, 6, 6, 0.00053306100836\n",
      "6, 6, 6, 0.00145979593393\n",
      "6, 7, 6, 0.000504371044989\n",
      "7, 7, 6, 0.000187245110848\n"
     ]
    }
   ],
   "source": [
    "for t in range(20):\n",
    "    for l in range(NN.ln-1):\n",
    "        NN.neuron_proliferate(l, int(0.1*NN.ly[l].nn) + 1)\n",
    "\n",
    "    for i in range(100):\n",
    "        NN.batch_fit(X,Y,step=0.1, descent_method=\"Rprop\")\n",
    "        if NN.max_cs < 0.0001:\n",
    "            break\n",
    "\n",
    "    for l in range(NN.ln-1):\n",
    "        NN.neuron_refined(l, X,((NN.dimension()/(10000))**2)/(NN.ly[l].nn))\n",
    "        print(NN.ly[l].nn, end=\", \")\n",
    "\n",
    "    for i in range(100):\n",
    "        NN.batch_fit(X,Y,step=0.1, descent_method=\"Rprop\")\n",
    "        if NN.max_cs < 0.0001:\n",
    "            break\n",
    "\n",
    "    print(NN.validate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    NN.batch_fit(X,Y,step=0.5, descent_method=\"Rprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10, 10\n"
     ]
    }
   ],
   "source": [
    "for l in range(NN.ln-1):\n",
    "    print(NN.ly[l].nn, end= \", \")\n",
    "    NN.neuron_refined(l, None, 0.0001)\n",
    "    print(NN.ly[l].nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1.97488787516\n",
      "0 2 0.198389442508\n",
      "0 3 0.0773856446697\n",
      "1 2 0.0856913391978\n",
      "1 3 0.0664770708499\n",
      "2 3 0.0453495495103\n"
     ]
    }
   ],
   "source": [
    "for i in range(NN.ln-1):\n",
    "    for j in range(i+1, NN.ln):\n",
    "        rr = NN.inter_layer_linear_regression((i,j))\n",
    "        print(i, j, np.sqrt(rr[1].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnistloader = MNIST(\"../python-mnist/data/\")\n",
    "training_data = mnistloader.load_training()\n",
    "X = np.array(training_data[0])\n",
    "X = (2*X/255) - 1. # to [-1, +1]\n",
    "\n",
    "Y = np.zeros((60000, 10))\n",
    "for i in range(Y.shape[0]):\n",
    "    Y[i][training_data[1][i]] = 1.\n",
    "\n",
    "testing_data = mnistloader.load_testing()\n",
    "X_test = np.array(testing_data[0])\n",
    "X_test = (2*X_test/255) - 1. # to [-1, +1]\n",
    "\n",
    "Y_test = np.zeros((10000, 10))\n",
    "for i in range(Y_test.shape[0]):\n",
    "    Y_test[i][testing_data[1][i]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(60000)\n",
    "X_train = X[shuffle[:56000]]\n",
    "Y_train = Y[shuffle[:56000]]\n",
    "X_valid = X[shuffle[56000:]]\n",
    "Y_valid = Y[shuffle[56000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = DogikoLearn(loss_function=\"ce\")\n",
    "NN.rs_extend_regularizer(0.001, 5.)\n",
    "NN.set_training_data(X_train, Y_train)\n",
    "NN.set_validation_data(X_valid, Y_valid)\n",
    "NN.add_layer(Layer(300, Hypertan()))\n",
    "NN.add_layer(Layer(100, Hypertan()))\n",
    "NN.add_layer(Layer(10, Softmax()))\n",
    "NN.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN.load_weight(\"MNIST-model-300-100-hu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300, 100, 0.16583 0.54442 0.9275\n"
     ]
    }
   ],
   "source": [
    "for t in range(1):\n",
    "    shuffle = np.random.permutation(60000)\n",
    "    X_train = X[shuffle[:56000]]\n",
    "    Y_train = Y[shuffle[:56000]]\n",
    "    X_valid = X[shuffle[56000:]]\n",
    "    Y_valid = Y[shuffle[56000:]]\n",
    "    NN.set_training_data(X_train, Y_train)\n",
    "    NN.set_validation_data(X_valid, Y_valid)\n",
    "    \n",
    "    for l in range(NN.ln-1):\n",
    "        NN.neuron_proliferate(l, 10, 0.01/NN.ly[l+1].dimension())\n",
    "    \n",
    "    NN.reset_cs(0.01)\n",
    "    NN.train(500, descent_method=\"Rprop\")\n",
    "    \n",
    "    NN.neuron_refined(0, X, -300)\n",
    "    NN.neuron_refined(1, X, -100)\n",
    "    for l in range(NN.ln-1):\n",
    "        print(NN.ly[l].nn, end=\", \")\n",
    "    \n",
    "    NN.reset_cs(0.01)\n",
    "    NN.train(300, descent_method=\"Rprop\")\n",
    "    \n",
    "    print(round(NN.training_error(), 5),\n",
    "          round(NN.validation_error(), 5),\n",
    "          ((NN.prediction(NN.vx).argmax(axis=1) == np.array(training_data[1])[shuffle[56000:]]).sum())/NN.vx.shape[0]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN.save_weight(\"MNIST-model-300-100-hu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92749999999999999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((NN.prediction(NN.vx).argmax(axis=1) == np.array(training_data[1])[shuffle[56000:]]).sum())/NN.vx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92500000000000004"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((NN.prediction(X_test).argmax(axis=1) == np.array(testing_data[1])).sum())/X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnistloader = MNIST(\"../python-mnist/data/\")\n",
    "training_data = mnistloader.load_training()\n",
    "X = np.array(training_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"/Users/dogiko/Documents/mnist_train_data.txt\", \"w\")\n",
    "for l in range(X.shape[0]):\n",
    "    temp_string = \"\"\n",
    "    for c in range(784):\n",
    "        temp_string += str(X[l][c]).zfill(3)\n",
    "    text_file.write(temp_string + \"\\n\")\n",
    "\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save mnist as txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnistloader = MNIST(\"../python-mnist/data/\")\n",
    "training_data = mnistloader.load_training()\n",
    "X_train = np.array(training_data[0])\n",
    "\n",
    "Y_train = np.zeros((X_train.shape[0], 10))\n",
    "for i in range(Y_train.shape[0]):\n",
    "    Y_train[i][training_data[1][i]] = 1\n",
    "\n",
    "testing_data = mnistloader.load_testing()\n",
    "X_test = np.array(testing_data[0])\n",
    "\n",
    "Y_test = np.zeros((X_test.shape[0], 10))\n",
    "for i in range(Y_test.shape[0]):\n",
    "    Y_test[i][testing_data[1][i]] = 1\n",
    "\n",
    "X_train = X_train.astype(int)\n",
    "Y_train = Y_train.astype(int)\n",
    "X_test = X_test.astype(int)\n",
    "Y_test = Y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"mnist-npy/train_data.npy\", X_train)\n",
    "np.save(\"mnist-npy/train_label.npy\", Y_train)\n",
    "np.save(\"mnist-npy/test_data.npy\", X_test)\n",
    "np.save(\"mnist-npy/test_label.npy\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data to txt\n",
    "text_file = open(\"/Users/dogiko/Documents/mnist_txt/train_data.txt\", \"w\")\n",
    "for i in range(X_train.shape[0]):\n",
    "    temp_string = \"\"\n",
    "    for j in range(784):\n",
    "        temp_string += str(X_train[i][j]).zfill(3)\n",
    "    \n",
    "    text_file.write(temp_string + \"\\n\")\n",
    "\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "# training label to txt\n",
    "text_file = open(\"/Users/dogiko/Documents/mnist_txt/train_label.txt\", \"w\")\n",
    "for i in range(Y_train.shape[0]):\n",
    "    temp_string = \"\"\n",
    "    for j in range(10):\n",
    "        temp_string += str(Y_train[i][j])\n",
    "    \n",
    "    text_file.write(temp_string + \"\\n\")\n",
    "\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "# testing data to txt\n",
    "text_file = open(\"/Users/dogiko/Documents/mnist_txt/test_data.txt\", \"w\")\n",
    "for i in range(X_test.shape[0]):\n",
    "    temp_string = \"\"\n",
    "    for j in range(784):\n",
    "        temp_string += str(X_test[i][j]).zfill(3)\n",
    "    \n",
    "    text_file.write(temp_string + \"\\n\")\n",
    "\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "# testing label to txt\n",
    "text_file = open(\"/Users/dogiko/Documents/mnist_txt/test_label.txt\", \"w\")\n",
    "for i in range(Y_test.shape[0]):\n",
    "    temp_string = \"\"\n",
    "    for j in range(10):\n",
    "        temp_string += str(Y_test[i][j])\n",
    "    \n",
    "    text_file.write(temp_string + \"\\n\")\n",
    "\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((6, 10000000))\n",
    "Y = np.zeros((6, 10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[0] = np.random.normal(0, 1, (1,10000000))\n",
    "Y[0] = 2.3377270891440238*(1-1/(abs(X[0])+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    X[i] = X[0]**(i+1)\n",
    "    Y[i] = Y[0]**(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.05669534e-04,   9.99658613e-01,  -6.88149692e-04,\n",
       "         2.99755337e+00,  -2.13604835e-03,   1.49903271e+01])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9002696 ,  1.00007725,  1.2233404 ,  1.58797483,  2.1491513 ,\n",
       "        3.00215376])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5.275685  ,   27.8328522 ,  146.83736082,  774.66766164])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(X).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9866143])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTanh.trans(2.5*np.ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5811388300841898"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3377270891440238"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1/0.18298369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f8f7a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(100), 1- 1/((np.arange(100)/100)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ter = (5,20,10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7662812973353983"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(20).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = np.arange(20)\n",
    "foo[(foo<15)&(foo>5)]=0\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
